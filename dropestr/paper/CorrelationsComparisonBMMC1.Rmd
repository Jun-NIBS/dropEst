---
title: "Comparison of clusters"
output: 
  html_document:
    df_print: kable
    theme: cerulean
    toc: true
    number_sections: true
  html_notebook: default
---

```{r, include=FALSE}
library(dropestr)
library(ggplot2)
library(ggsci)
library(ggpubr)
library(ggrastr)
library(dplyr)
library(Matrix)
library(parallel)
library(pagoda2)
library(reshape2)

source("./Functions/Functions.R")
source("./Functions/PlotFuncs.R")
source("./Functions/VariationAnalysisFuncs.R")

knitr::opts_chunk$set(fig.width=5, fig.height=3, echo=FALSE, warning=FALSE, message=FALSE)

theme_set(theme_base)

kDatasetName <- 'frozen_bmmc_healthy_donor1'
kPlotsDir <- paste0('~/Data/Plots/Paper/Review/UmiErrors/', kDatasetName, '/')
kDataPath <- '/d0-mendel/home/viktor_petukhov/Data/10x/frozen_bmmc_healthy_donor1/est_11_10_umi_quality/'
```

```{Rcpp}
#include <Rcpp.h>
#include <vector>
#include <string>

// [[Rcpp::export]]
std::vector<int> pairwise_hamming(const std::vector<std::string> &strs) {
  std::vector<int> distances;
  for (int i = 0; i < strs.size(); ++i) {
    for (int j = i + 1; j < strs.size(); ++j) {
      const std::string &str1 = strs[i];
      const std::string &str2 = strs[j];
      if (str1.length() != str2.length())
        Rcpp::stop("Strings must have the same length");
      
      int ed = 0;
      for (int c_id = 0; c_id < str1.length(); ++c_id) {
        if (str1[c_id] != str2[c_id]) {
          ed++;
        }
      }
      distances.push_back(ed);
    }
  }
  
  return distances;
}
```

```{r}
GetPagoda <- function(cm, n.cores=10, clustering.type='infomap', embeding.type='tSNE', verbose=TRUE) {
  library(pagoda2)
  r <- Pagoda2$new(cm, modelType='plain', trim=5, n.cores=n.cores, verbose=verbose)
  r$adjustVariance(plot=F, do.par=F, gam.k=10, verbose=verbose)

  r$calculatePcaReduction(nPcs=100, n.odgenes=1000, maxit=1000)
  r$makeKnnGraph(k=30,type='PCA', center=T,distance='cosine',weight.type='none', verbose=verbose)
  if (clustering.type == 'infomap') {
    r$getKnnClusters(method=infomap.community,type='PCA',name='infomap')
  } else if (clustering.type == 'multilevel') {
    r$getKnnClusters(method=multilevel.community,type='PCA',name='multilevel')
  } else stop("Unknown clustering  type")

  if ('largeVis' %in% embeding.type) {
    r$getEmbedding(type='PCA', embeddingType = 'largeVis')
  }
  
  if ('tSNE' %in% embeding.type) {
    r$getEmbedding(type='PCA', perplexity=30, embeddingType = 'tSNE')
  }
  
  return(r)
}
```

```{r}
holder <- readRDS(paste0(kDataPath, 'bmmc.rds'))
if (length(holder$reads_per_umi_per_cell$reads_per_umi[[1]][[1]]) != 2) stop("Quality must be provided")

umi_distribution <- GetUmisDistribution(holder$reads_per_umi_per_cell$reads_per_umi)
umi_probs <- umi_distribution / sum(umi_distribution)
# collisions_info <- FillCollisionsAdjustmentInfo(umi_probs, max(holder$cm))
# length(holder$reads_per_umi_per_cell$reads_per_umi)
```

```{r}
# corrected_cms <- list()
# max_upg <- sapply(holder$reads_per_umi_per_cell$reads_per_umi, length) %>% max()
# max_upg <- collisions_info[max_upg]
# correction_info <- PrepareUmiCorrectionInfo(umi_probs, max_upg, verbosity.level=1)
# 
# corrected_cms$bayesian <- CorrectUmiSequenceErrors(holder$reads_per_umi_per_cell, method='Bayesian', return='matrix', 
#                                                    collisions.info=collisions_info, umi.probabilities=umi_probs, 
#                                                    correction.info=correction_info, verbosity.level=2, mc.cores=30)
# 
# corrected_cms$cluster <- CorrectUmiSequenceErrors(holder$reads_per_umi_per_cell, method='Classic', return='matrix',
#                                                   collisions.info=collisions_info, umi.probabilities=umi_probs, 
#                                                   verbosity.level=2, mc.cores=30)
# 
# corrected_cms$`cluster-neq` <- CorrectUmiSequenceErrors(holder$reads_per_umi_per_cell, method='Classic', return='matrix',
#                                                     mult=1+1e-4, collisions.info=collisions_info, umi.probabilities=umi_probs, 
#                                                     verbosity.level=2, mc.cores=30)
# 
# corrected_cms$directional <- CorrectUmiSequenceErrors(holder$reads_per_umi_per_cell, method='Classic', return='matrix',
#                                                   mult=2, collisions.info=collisions_info, umi.probabilities=umi_probs, 
#                                                   verbosity.level=2, mc.cores=30)
# 
# corrected_cms$raw <- holder$cm
# corrected_cms$raw@x <- collisions_info[corrected_cms$raw@x]
# 
# saveRDS(corrected_cms, paste0(kDataPath, 'cms2.rds'))
```

```{r}
corrected_cms <- readRDS(paste0(kDataPath, 'cms2.rds'))
```

# Analysis
```{r}
corrected_cms <- lapply(corrected_cms, function(cm) cm[grep("^[^;]+$", rownames(cm)), ])
names(corrected_cms) <- c('Bayesian', 'cluster', 'cluster-neq', 'directional', 'raw')
```

Create pagoda object for raw data:
```{r, message=FALSE, warning=FALSE}
kClusteringType <- 'infomap'
r <- GetPagoda(corrected_cms$raw, n.cores=25, clustering.type=kClusteringType, embeding.type='tSNE', verbose=F)
clusters <- r$clusters$PCA[[kClusteringType]]

# r_s1 <- GetPagoda(corrected_cms$cluster, n.cores=25, clustering.type=kClusteringType, embeding.type='tSNE', verbose=F)
# clusters <- r_s1$clusters$PCA[[kClusteringType]]
```

```{r}
kMinCellsPerCluster <- 50
# PlotPagodaEmbeding(r_s1, embeding.type='tSNE', clustering.type=kClusteringType, mark.clusters=T, 
#                    show.legend=F, min.cluster.size=kMinCellsPerCluster, size=0.5, alpha=0.5, show.ticks=F, plot.na=T) + 
#   scale_color_hue(l=55)

PlotPagodaEmbeding(r, embeding.type='tSNE', clustering.type=kClusteringType, mark.clusters=T, 
                   show.legend=F, min.cluster.size=kMinCellsPerCluster, size=0.5, alpha=0.5, show.ticks=F, plot.na=T) + 
  scale_color_hue(l=55)
```

```{r}
real_clusters <- which(table(clusters) > kMinCellsPerCluster)
```

```{r}
rs <- list()
for (n in names(corrected_cms)) {
  sink("/dev/null"); rs[[n]] <- Pagoda2$new(corrected_cms[[n]], modelType='plain', trim=5, n.cores=5, verbose=F); sink()
  # rs[[n]]$adjustVariance(plot=F, do.par=F, gam.k=10)
}

norm_cms <- lapply(rs, function(r) t(r$counts))
```

## Magnitude of correction
Raw expression:

```{r, fig.width=7, fig.height=5}
umis_per_gene <- lapply(corrected_cms, function(cm) cm@x)
umis_per_gene <- lapply(umis_per_gene, function(x) x[umis_per_gene$raw > 1]) %>% as.data.frame()
ggplot(melt(umis_per_gene, id.vars='raw'), aes(x = raw, y = raw - value, color = variable)) +
  geom_point_rast(size = 1, alpha=0.05) +
  # geom_smooth() +
  # facet_wrap(~variable) +
  scale_x_log10() + scale_y_log10() + annotation_logticks() +
  labs(x = 'Raw expression', y = 'Expression change') +
  # theme_pdf(legend.pos = 'none') +
  theme_pdf(legend.pos = c(0.05, 1)) +
  guides(color = guide_legend(override.aes=list(alpha=1), title='Correction'))
```

Normalized expression:

```{r, fig.width=7, fig.height=5}
norm_umis_per_gene <- lapply(norm_cms, function(cm) cm@x)
norm_umis_per_gene <- lapply(norm_umis_per_gene, function(x) x[(umis_per_gene$raw > 1) & (umis_per_gene$raw != umis_per_gene$cluster)]) %>% as.data.frame()
ggplot(melt(norm_umis_per_gene, id.vars='raw')) +
  geom_point_rast(aes(x = raw, y = 1e-6 + raw - value, color = variable), size = 0.5, alpha=0.05) +
  facet_wrap(~variable) +
  scale_x_log10() + scale_y_log10() + annotation_logticks(sides='b') +
  labs(x = 'Raw exression', y = '1e-6 + Exression change') +
  theme_pdf(legend.pos = 'none') +
  theme(strip.text.x=element_text(margin=margin(t=3, b=3, unit='pt')))
```

## Target correlations
Let's pick genes with large correction (above 20%), which are expressed in at least half of cells in cluster. 
These genes are selected separately for each cluster.
```{r, warning=FALSE}
correlations_info <- mclapply(real_clusters, TargetClusterCorrelation, clusters, corrected_cms, 
                              correction.threshold=0.2, expression.frac.threshold=0.5, mc.cores=5)
correlations <- lapply(correlations_info, `[[`, 'correlations') %>% bind_rows() %>% 
  mutate(Diff = (Correlation - CorrelationRaw) / CorrelationRaw)
```

Correlation change accumulated by all clusters:  
```{r, fig.width=6, fig.height=6, warning=FALSE, message=FALSE}
plot_df <- correlations %>% filter(Correction != 'raw')
gg1 <- ggplot(plot_df, aes(x=Diff, color=Correction)) + 
  geom_density() +
  xlim(-0.1, 0.15) +
  labs(x='Relative difference in correlation after corrections', y='Density') +
  theme_pdf(legend.pos=c(0, 1))

gg2 <- ggplot(correlations, aes(x=Correlation, color=Correction), guides=F) +
  geom_density() +
  xlim(0.5, 1.0) +
  labs(x='Spearman correlations', y='Density') +
  theme_pdf(legend.pos=c(0, 1))

cowplot::plot_grid(gg1, gg2, nrow=2, align='v')
```

Correlation distribution by each cluster (just to ensure that nothing weird happens):  
```{r, fig.width=7, fig.height=7, warning=FALSE, message=FALSE}
gg2 + facet_wrap(~Cluster) + scale_x_continuous(limits=c(0, 1), breaks=c(0, 0.5, 1)) + 
  theme(strip.text.x=element_text(margin=margin(t=1, b=1, unit='pt'))) +
  theme_pdf(legend.pos=c(1, 0))
```

### Analysis
To understand the reason of the difference between correlations, we can look at a fixe pair of cells.
To present these pairs we can plot heatmap, which would be the graphical representation of the contingency table for these cells.
Numbers above the plots denote Spearman correlation. Here, all expression values above the x/y border were set to the border value.
```{r}
ggplot(as.data.frame(corrected_cms$raw[genes, barcodes] %>% as.matrix()) %>% `colnames<-`(c('C1','C2'))) + geom_point(aes(x = rank(C1), y = rank(C2)))
ggplot(as.data.frame(corrected_cms$Bayesian[genes, barcodes] %>% as.matrix()) %>% `colnames<-`(c('C1','C2'))) + geom_point(aes(x = rank(C1), y = rank(C2)))
ggplot(as.data.frame(corrected_cms$cluster[genes, barcodes] %>% as.matrix()) %>% `colnames<-`(c('C1','C2'))) + geom_point(aes(x = rank(C1), y = rank(C2)))
```

```{r, message=FALSE, fig.width=8, fig.height=6}
cl_correlations <- inner_join(correlations %>% filter(Correction == 'cluster'), 
                              correlations %>% filter(Correction == 'Bayesian') %>% 
                                select(Barcode1, Barcode2, CorrelationBayesian=Correlation), by=c('Barcode1', 'Barcode2')) %>%
  filter(Correlation > 0.5, CorrelationRaw > 0.5)

t_row <- cl_correlations[cl_correlations %>% mutate(Diff = Correlation - CorrelationBayesian) %>% .$Diff %>% which.max(), ]
barcodes <- unlist(t_row[, c('Barcode1', 'Barcode2')])
genes <- correlations_info[[paste0(t_row$Cluster)]]$genes

PlotCorrelationHeatmaps(corrected_cms, correlations, genes, barcodes, 50, labs.step=5)
```

We can see that simple decreasing of expression levels for moderately expressed genes leads to the correlation increase.

### Filtration of lowly expressed genes
Let's use another filtration criteria. Now we pick only genes with correction above 5% and with trimmed mean (level 10%) 
of non-normalized expression level above 10.
```{r, warning=FALSE}
correlations_info <- mclapply(real_clusters, TargetClusterCorrelation, clusters, corrected_cms, 
                            correction.threshold=0.05, expression.total.threshold=10, mc.cores=5)
correlations <- lapply(correlations_info, `[[`, 'correlations') %>% bind_rows() %>% 
  mutate(Diff = (Correlation - CorrelationRaw) / CorrelationRaw)
```

Number of genes per cluster:
```{r}
lapply(correlations_info, `[[`, 'genes') %>% sapply(length)
```

Let's remove all clusters with less than 80 genes.  

```{r, fig.width=6, fig.height=7, message=FALSE, warning=FALSE}
plot_clusters <- lapply(correlations_info, `[[`, 'genes') %>% sapply(length) %>% (function(x) which(x > 80))
plot_df <- correlations %>% filter(Cluster %in% plot_clusters)
gg1 <- ggplot(plot_df %>% filter(Correction != 'raw'), aes(x=Diff, color=Correction)) + 
  geom_density() + xlim(-0.3, 0.3) + 
  labs(x='Difference in correlations with raw', y='Density') +
  theme_pdf(legend.pos=c(1, 1))

gg2 <- ggplot(plot_df, aes(x=Correlation, color=Correction), guides=F) +
  geom_density() +
  labs(x='Spearman correlations', y='Density') +
  xlim(0.0, 0.9) + theme_pdf(legend.pos=c(1, 1))

cowplot::plot_grid(gg1, gg2, nrow=2, align='v')
```

```{r, message=FALSE, fig.width=8, fig.height=6}
cl_correlations <- correlations %>% filter(Correction == 'cluster', Correlation > 0.5, CorrelationRaw > 0.1)
t_row <- cl_correlations[cl_correlations %>% .$Diff %>% which.max(), ]
barcodes <- unlist(t_row[, c('Barcode1', 'Barcode2')])
genes <- correlations_info[[paste0(t_row$Cluster)]]$genes
PlotCorrelationHeatmaps(corrected_cms, correlations, genes, barcodes, 30, labs.step=5)
```

These results looks too weird to rely on them.

## Variation
Variation of a single gene expression within fixed cluster (after normalization) is another possible measure. 
It allows us to increase gene filtration thresholds, as now we analyze single genes, but not gene vectors. Here we used
only genes with the correction size > 10% and median normalized expression > 10.  

```{r}
var_dfs <- lapply(real_clusters, function(cl) 
  ExpressedGenesVariation(norm_cms, clusters, cluster.num=cl, mean.correction.threshold=0.1, 
                          median.expression.threshold=10))

var_df <- var_dfs %>% bind_rows(.id='Cluster') %>% mutate(Cluster = as.integer(Cluster))
```

```{r}
plot_df <- var_df %>% group_by(Gene, Correction, Cluster) %>% 
  summarise(Variation = IQR(Expression), VariationRaw = IQR(ExpressionRaw), 
            VariationDiff = Variation - VariationRaw, Mean = mean(Expression, trim=0.1))

ggplot(plot_df) + geom_density(aes(x=VariationDiff, color=Correction)) + 
  xlim(-10, 10) + 
  labs(x='Variation difference after the correction', y='Density') +
  theme_pdf(legend.pos=c(1, 1))
```

Dependency between mean and variation:  
```{r}
gg_variation <- ggplot(plot_df, aes(x=Mean, y=Variation, color=Correction)) + 
  geom_point(size=1) + 
  geom_smooth(method='lm') +
  scale_x_log10() + scale_y_log10() + 
  labs(x='Trimmed mean expression (10% trim level)', y='Interquartile range') +
  theme_pdf(legend.pos=c(0, 1))

gg_variation
```

According to this plot, `cluster` and `directional` corrections increase variation coeffitient.

## Difference between clusters
```{r}
GetOverexpressedGenes <- function(cm.raw, clusters, cluster.num, median.expression.threshold=0) {
  cluster.cm <- cm.raw[, names(clusters)[clusters == cluster.num]]
  cluster.cm <- cluster.cm[Matrix::rowSums(cluster.cm) > 0, ] %>% as.matrix()

  med.expression <- apply(cluster.cm, 1, mean, trim=0.1)
  return(names(med.expression)[med.expression >= median.expression.threshold])
}

overexpressed_genes <- lapply(norm_cms, function(cm) lapply(real_clusters, function(cl) GetOverexpressedGenes(cm, clusters, cl, median.expression.threshold=5)))
overexpressed_genes <- Reduce(union, lapply(overexpressed_genes, function(g) Reduce(union, g)))
# length(overexpressed_genes)
```

Another measure is ability to distinguish differentially expressed genes. To fild highly expressed genes we estimated mean
normalized gene expression level within each cluster (10% trimmed mean was used). Genes with me expression > 5 for at least 
one cluster were considered as highly-expressed.

```{r, fig.width=8, fig.height=8}
expr_mats <- lapply(norm_cms, function(cm) sapply(real_clusters, function(cl) cm[overexpressed_genes, names(clusters)[clusters == cl]] %>% apply(1, mean, trim=0.2)))
clust_row <- hclust(dist(expr_mats$raw))
clust_col <- hclust(dist(t(expr_mats$raw)))

plot_dfs <- lapply(expr_mats, function(mat) as.data.frame(mat) %>% 
                     tibble::rownames_to_column('Gene') %>% 
                     reshape2::melt(id.vars='Gene', variable.name='Cluster', value.name='MeanExpression') %>%
                     dplyr::mutate(Cluster = factor(Cluster, levels(Cluster)[clust_col$order]),
                                   Gene = factor(Gene, rownames(mat)[clust_row$order])))

ggs <- lapply(names(plot_dfs), function(n) 
  ggplot(plot_dfs[[n]]) + geom_tile(aes(x=Cluster, y=Gene, fill=log10(1 + MeanExpression))) + 
  scale_fill_distiller(palette='RdYlBu', limits=c(0, 3)) +
  ggtitle(n) +
  theme(axis.text.y=element_blank(), plot.margin=margin(r=5, t=5, unit='pt')) + rremove('xylab'))

colorbar_guide <- ggplot2::guide_colorbar(direction='horizontal', title.position='top', title='log10(Mean expression)', barwidth=unit(2, 'in'))
legend <- get_legend(ggs[[1]] + ggplot2::guides(fill = colorbar_guide))

cowplot::plot_grid(plotlist=c(lapply(ggs, `+`, rremove('legend')), list(legend)), align='hv', axis='t')
```

```{r}
tested_genes <- rev(rownames(expr_mats$raw)[clust_row$order])[38:54]
tested_clusters <- colnames(expr_mats$raw)[clust_col$order][7:ncol(expr_mats$raw)] %>% as.integer()
```

We can see that a lot of clusters have the same set of highly-expressed genes. Let's choose some such genes and clusters.

Genes:
```{r}
tested_genes
```

Clusters:
```{r}
tested_clusters
```

Dependency between 10% trimmed mean and interquartile range for data, aggreagted by genes and clusters:

```{r}
tested_df <- lapply(tested_genes, function(g) lapply(tested_clusters, function(cl) 
  lapply(norm_cms, `[`, g, names(clusters)[clusters == cl]) %>% as.data.frame()) %>% setNames(tested_clusters) %>% bind_rows(.id='Cluster')) %>% 
  setNames(tested_genes) %>% bind_rows(.id='Gene') %>% 
  mutate(Cluster = as.integer(Cluster)) %>%
  melt(id.vars=c('Gene', 'Cluster'), variable.name='Correction', value.name='Expression') %>% 
  filter(Expression > 0) %>% 
  group_by(Gene, Cluster, Correction) %>% 
  summarise(Mean = mean(Expression, trim=0.1), Variation = IQR(Expression))

ggplot(tested_df, aes(x=Mean, y=Variation, color=Correction)) + 
  geom_point(alpha=0.7, size=1) + 
  geom_smooth(method='lm') +
  theme_pdf(legend.pos=c(0, 1))
```

This plot is quite similar to the previous one of this type.  
Here is the same plot by genes, expression is averaged by cells within each cluster:

```{r}
plot_df <- tested_df %>% group_by(Correction, Gene) %>% 
  summarise(Variation = IQR(Mean), Mean = mean(Mean, trim=0.1))

ggplot(plot_df, aes(x=Mean, y=Variation, color=Correction)) + 
  geom_point(alpha=0.7, size=1) + 
  geom_smooth(method='lm') +
  theme_pdf(legend.pos=c(0, 1))
```

These lines have almost the same slope. Thus, no difference can be shown.

## Edit distances
Comparison of edit distances with the expected distribution, similar to UMI Tools paper.
```{r}
SampleNoReps <- function(size, ids, probs) {
  umis <- unique(sample(ids, size=size, prob=probs, replace=T))
  while (length(umis) < size) {
    umis <- unique(c(umis, sample(ids, size=size, prob=probs, replace=T)))
  }
  
  return(umis[1:size])
}

ed_probs <- sapply(1:100, function(i) SampleNoReps(1000, names(umi_probs), umi_probs) %>% pairwise_hamming()) %>% 
  dropestr::ValueCounts(return_probs=T)
ed_probs <- ed_probs[paste0(1:5)]
```

```{r}
# corrected_reads <- list()
# corrected_reads$bayesian <- CorrectUmiSequenceErrors(holder$reads_per_umi_per_cell, method='Bayesian', return='reads', 
#                                                    collisions.info=collisions_info, umi.probabilities=umi_probs, 
#                                                    verbosity.level=2, mc.cores=30)
# 
# corrected_reads$cluster <- CorrectUmiSequenceErrors(holder$reads_per_umi_per_cell, method='Classic', return='reads',
#                                                   collisions.info=collisions_info, umi.probabilities=umi_probs, 
#                                                   verbosity.level=2, mc.cores=30)
# 
# corrected_reads$`cluster-neq` <- CorrectUmiSequenceErrors(holder$reads_per_umi_per_cell, method='Classic', return='reads',
#                                                     mult=1+1e-4, collisions.info=collisions_info, umi.probabilities=umi_probs, 
#                                                     verbosity.level=2, mc.cores=30)
# 
# corrected_reads$directional <- CorrectUmiSequenceErrors(holder$reads_per_umi_per_cell, method='Classic', return='reads',
#                                                   mult=2, collisions.info=collisions_info, umi.probabilities=umi_probs, 
#                                                   verbosity.level=2, mc.cores=30)
# 
# corrected_reads$raw <- holder$reads_per_umi_per_cell$reads_per_umi
# umis_per_gene <- mclapply(corrected_reads, lapply, names, mc.cores=5)
# saveRDS(corrected_reads, paste0(kDataPath, 'corrected_rpus.rds'))
# saveRDS(umis_per_gene, paste0(kDataPath, 'corrected_umis_per_gene.rds'))
```

```{r}
umis_per_gene <- readRDS(paste0(kDataPath, 'corrected_umis_per_gene.rds'))
```

```{r}
obs_eds <- mclapply(umis_per_gene, function(reads) 
  mclapply(reads, pairwise_hamming, mc.cores=8) %>% unlist(), mc.cores=5)

obs_ed_probs <- mclapply(obs_eds, dropestr::ValueCounts, return_probs=T, mc.cores=5) %>%
  lapply(`[`, paste0(1:5)) %>% lapply(function(x) {x[is.na(x)] <- 0; setNames(x, paste0(1:5))}) %>% 
  as.data.frame()

obs_ed_sds <- mclapply(obs_eds, function(x) sd(x) / (length(x) %>% sqrt()), mc.cores=5) %>% unlist()
```

Here, confidence intervals are negligable and not shown:
```{r}
plot_df <- (abs(obs_ed_probs - ed_probs)) %>% mutate(EditDistance=1:5) %>% 
  melt(variable.name = 'Correction', value.name = 'Error', id.vars = 'EditDistance')

(text_df <- as.data.frame(abs(obs_ed_probs - ed_probs) / ed_probs) %>% mutate(EditDistance=1:5) %>% 
  melt(variable.name = 'Correction', value.name = 'Error', id.vars = 'EditDistance') %>%
  mutate(x=EditDistance + (as.integer(Correction) - 3) / 5.5, y=100 * plot_df$Error + 0.1))

breaks <- seq(0, 100, by=25)
ggplot(plot_df) + 
  geom_bar(aes(x = EditDistance, y = 100 * Error, fill = Correction), color = 'black', position = 'dodge', stat = 'identity') + 
  labs(x = 'Edit distance', y = 'Probability error') +
  geom_text(aes(x=x, y=y, label=format(100*Error, digits=0)), text_df) +
  scale_y_continuous(expand=c(0.0, 0), limits=c(0, 3)) +
  theme_pdf(legend.pos=c(1, 1)) +
  theme(panel.grid.major=element_blank())
```

```{r, fig.width=8, fig.height=4}
plot_df <- (abs(obs_ed_probs - ed_probs) / ed_probs) %>% mutate(EditDistance=1:5) %>% 
  melt(variable.name = 'Correction', value.name = 'Error', id.vars = 'EditDistance')

text_df <- data.frame(Prob=ed_probs, EditDistance=1:5, x=1:5 - 0.03) %>%
  mutate(y = plot_df %>% group_by(EditDistance) %>% summarise(Error=max(Error)) %>% .$Error * 100 + 3.5)

breaks <- seq(0, 100, by=25)
gg_eds <- ggplot(plot_df) + 
  geom_bar(aes(x = EditDistance, y = 100 * Error, fill = Correction), color = 'black', position = 'dodge', stat = 'identity') + 
  labs(x = 'Edit distance', y = 'Relative probability error, %') +
  geom_text(aes(x=x, y=y, label=format(Prob, digits=2)), text_df) +
  scale_y_continuous(expand=c(0.0, 0), limits=c(0, 107), minor_breaks=breaks - 1e-3, breaks=breaks) +
  scale_x_continuous(minor_breaks=NULL) +
  theme_pdf(legend.pos=c(1, 1)) +
  theme(panel.grid.major=element_blank())

cowplot::plot_grid(gg_variation + annotation_logticks() + rremove("legend"), gg_eds, labels="AUTO")
ggsave(paste0(kPlotsDir, 'figure_correction.pdf'))
```
